# -*- coding: utf-8 -*-
"""Major_Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QMSB122ediUxIU04ngOaJWqEiaDaY3aM
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split

#Accessing data(tsv file)
df = pd.read_table('/content/Restaurant_Reviews (1).tsv')
df

df.info()

df.isnull().sum()

# EDA(exploratory data analysis)
sns.distplot(df.Liked)
plt.show()

# First using Count Vectorizer:
from sklearn.feature_extraction.text import CountVectorizer
vect = CountVectorizer(stop_words = 'english')

df = df.drop_duplicates(keep = 'last')
df

df['Review'][990]

df['Liked'][990]

df['Review'][97]

df['Liked'][97]

df['Liked'].value_counts()

df['Liked'].value_counts().plot(kind='bar')
plt.show()

df['Liked'].value_counts().plot(kind='box')
plt.show()

#State Wise Review Analysis 
sns.barplot(x='Review',y='Liked',data=df)
plt.show()

x = df['Review'].values
y = df['Liked'].values

df.shape

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test = train_test_split(x,y,random_state = 0)

x_train.shape

x_test.shape

vect = CountVectorizer(stop_words = 'english')
x_train_vect = vect.fit_transform(x_train)
x_test_vect = vect.transform(x_test)

x_train_vect.toarray() # all text is converted into numerical values.

#METHOD 1:
from sklearn.svm import SVC  #from Support Vector Machine import support vector classifier
model = SVC()
model.fit(x_train_vect,y_train)

y_pred = model.predict(x_test_vect)
y_pred

from sklearn.metrics import accuracy_score
accuracy_score(y_pred,y_test)

#METHOD 2: Using Pipelines
# SVC + CountVectorizer
from sklearn.pipeline import make_pipeline
model2 = make_pipeline(CountVectorizer(),SVC())

model2.fit(x_train,y_train)
y_pred2 = model2.predict(x_test)
y_pred2

accuracy_score(y_pred2,y_test)

#METHOD 3: using NAIVE BAYES
from sklearn.naive_bayes import MultinomialNB
model3 = MultinomialNB()

model3.fit(x_train_vect,y_train)

y_pred3 = model3.predict(x_test_vect)
y_pred3

accuracy_score(y_pred3,y_test)

# METHOD 4: NB + CountVectorizer
from sklearn.pipeline import make_pipeline
model4 = make_pipeline(CountVectorizer(),MultinomialNB())

model4.fit(x_train,y_train)
y_pred4 = model4.predict(x_test)
y_pred4

accuracy_score(y_pred4,y_test)

# Using Tf-idf Vectorizer which is more advance than CountVectorizer!
from sklearn.feature_extraction.text import TfidfVectorizer
tfidf = TfidfVectorizer(stop_words = 'english')

# How to handle data(using Tf-idf Vectorizer) 
# NATURAL LANGUAGE PROCESSING
s = ['Excellent customer service. (EN) was very friendly, patient and helpful in helping us find what we were looking for.',
 'Excellent customer service from (EN)!! He helped clarify many questions I had regarding (Service)!']

op = tfidf.fit_transform(s).toarray()
op

print(len(tfidf.vocabulary_))

tfidf.vocabulary_

feature_names = tfidf.get_feature_names()
for col in op.nonzero()[1]:
  print(feature_names[col], ' - ', op[0, col])

# Moving further on given data set!
df.info()

df = df.drop_duplicates(keep = 'last')   #To remove all duplicate Reviews from dataframe.
df

df['Review'][990]

df['Liked'][990]

df['Review'][97]

df['Liked'][97]

df['Liked'].value_counts()

df['Liked'].value_counts().plot(kind='bar')
plt.show()

x = df['Review'].values
y = df['Liked'].values

df.shape

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test = train_test_split(x,y,random_state = 0)

x_train.shape

x_test.shape

tfidf = TfidfVectorizer(stop_words = 'english')
x_train_tfidf = tfidf.fit_transform(x_train)
x_test_tfidf = tfidf.transform(x_test)

x_train_tfidf.toarray() # all text is converted into numerical values.

#METHOD 1:
from sklearn.svm import SVC  #from Support Vector Machine import support vector classifier
model = SVC()
model.fit(x_train_tfidf,y_train)

y_pred = model.predict(x_test_tfidf)
y_pred

from sklearn.metrics import accuracy_score
accuracy_score(y_pred,y_test)

#METHOD 2: Using Pipelines
# SVC + TfidfVectorizer
from sklearn.pipeline import make_pipeline
model2 = make_pipeline(TfidfVectorizer(),SVC())

model2.fit(x_train,y_train)
y_pred2 = model2.predict(x_test)
y_pred2

accuracy_score(y_pred2,y_test)

#METHOD 3: using NAIVE BAYES
from sklearn.naive_bayes import MultinomialNB
model3 = MultinomialNB()

model3.fit(x_train_tfidf,y_train)

y_pred3 = model3.predict(x_test_tfidf)
y_pred3

accuracy_score(y_pred3,y_test)

# METHOD 4: NB + TfidfVectorizer
from sklearn.pipeline import make_pipeline
model4 = make_pipeline(TfidfVectorizer(),MultinomialNB())

model4.fit(x_train,y_train)
y_pred4 = model4.predict(x_test)
y_pred4

accuracy_score(y_pred4,y_test)

# WEBAPP using the model
import joblib
joblib.dump(model2,'Sentiment-Analysis')

import joblib
reload_model = joblib.load('Sentiment-Analysis')

reload_model.predict(['worst'])

reload_model.predict(['good'])

# TfidfVectorizer is used to create the model as it gave more accuracy than CountVectorizer!
# model2(SVC+TfidfVectorizer) model is used to create the app as it gave highest accuracy(0.8192771084337349) among all other model* 
#Creating webapp using STREAMLIT
!pip install streamlit --quiet

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# import joblib
# st.title("SENTIMENT ANALYSIS")
# reload_model = joblib.load('Sentiment-Analysis')
# ip = st.text_input("Enter the REVIEW: ") #Getting user input
# op = reload_model.predict([ip])[0]
# dict = {0 :'Negative', 1 : 'Positive'}
# if st.button('PREDICT'):
#   st.title(dict[op])
#

!streamlit run app.py & npx localtunnel --port 8501